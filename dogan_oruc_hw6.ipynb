{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of inputs:  -0.002113822030739876\n",
      "Standard deviation of inputs:  1.0009610853718647\n",
      "\n",
      "\n",
      "Mean of weights:  -0.0002697203343350954\n",
      "Standard deviation of weights:  1.0010529846224274\n",
      "\n",
      "\n",
      "Mean of inputs:  0.009486774567372234\n",
      "Standard deviation of inputs:  785.6157360311767\n"
     ]
    }
   ],
   "source": [
    "x = np.random.normal(0,1,1000000)\n",
    "w = np.random.normal(0,1,1000000)\n",
    "\n",
    "print(\"Mean of inputs: \", np.mean(x))\n",
    "print(\"Standard deviation of inputs: \", np.std(x))\n",
    "print(\"\\n\")\n",
    "print(\"Mean of weights: \", np.mean(w))\n",
    "print(\"Standard deviation of weights: \", np.std(w))\n",
    "print(\"\\n\")\n",
    "print(\"Mean of inputs: \", np.mean(784*x*w))\n",
    "print(\"Standard deviation of inputs: \", np.std(784*x*w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yukarıdaki örnekte görüldüğü üzere inputlar ve weightler için seçim yapılacak dağılımlar için örneklemler oluşturulmuştur. Weigthler birbirlerini etkilemeyecek şekilde seçildiğinden aslında tüm weightlerin 1 dağılım oluşturduğu düşünülebilir. Bu noktada seçilen weight miktarı kadar elde normal dağılım bulunduğu söylenebilir. Aynı şekilde inputların da normal dağılımlardan geldiği düşünüldüğünde aynı şekilde birden çok normal dağılımın elde olduğu söylenebilir. İnput değerimizin 784 tane olduğunu düşünelim. Bu noktada aynı şekilde 784 tane weightimiz bulunmaktadır. Bu noktadan sonra ikiye ayıracak olursak:\n",
    "\n",
    "<img src=\"var(xy).png\">\n",
    "\n",
    "- Başlangıçta her node için x*w değerlerinin varyanslarının hesaplanmalarını açıklayalım. Yukarıdaki formule bakıldığı takdirde X ve Y'nin aynı dağılımlara sahip olması ve birbirlerinden bağımsız olmalarından dolayı kovaryansları 0 olarak alınır. Her iki dağılım için de ortalamalar 0 elde edildiği için expected valueları 0 olacaktır. Bu noktada mantık olarak Var(x*y) direkt olarak iki dağılımın varyanslarının çarpımı olarak düşünülebilir.\n",
    "\n",
    "- Diğer bir nokta her x*w çarpımının toplanıp bir node eklenmesidir. Burada Var(x+y)'nin temelini alacak olursak iki varyansın toplamı eğer covaryansları 0 ise Var(X) + Var(Y) olarak düşünülebilir. Bu noktada covaryansın derinliğine inecek olursak. (x-E(x))*(y-E(y)) ye bakılması gerekmektedir. Dağılımlar aynı olduğu için ve ortalamaları 0 olduğu için direkt olarak x*y olarak düşünülebilir. Bu noktada ise - ve + kısımlar örtüşeceği için kovaryans 0 elde edilir. Bu nedenle tüm nodeların varyanslarının toplanması yeterli olacaktır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ödev 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"C:/Users/dogan/Desktop/kodluyoruz_bootcamp_102/Hafta5/data/mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): \n",
    "    return (x.exp()/(x.exp().sum(-1,keepdim=True)) + 1e-20).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(preds, actuals): \n",
    "    return -preds[range(actuals.shape[0]), actuals].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_acc(model):\n",
    "    return torch.stack([accuracy(model(xb), yb) for xb, yb in valid_dl]).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(preds, targets):\n",
    "    preds = log_softmax(preds)\n",
    "    return nll(preds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, yb): \n",
    "    return (torch.argmax(preds, dim=1, keepdim = True)==yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(preds, targets):\n",
    "    preds = log_softmax(preds)\n",
    "    return nll(preds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs=5, valid_epoch=5):\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            \n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb.squeeze())\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "        \n",
    "        if epoch % valid_epoch == 0:\n",
    "            print(validation_acc(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_files(p, fs, extensions = None):\n",
    "    p = Path(p) # to support / notation\n",
    "    res = [p/f for f in fs if not f.startswith(\".\") \n",
    "           and ((not extensions) or f'.{f.split(\".\")[-1].lower()}' in extensions)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, x, y): \n",
    "        self.x,self.y = x,y\n",
    "    def __len__(self): \n",
    "        return len(self.x)\n",
    "    def __getitem__(self, i): \n",
    "        return self.x[i].view(-1,1,28,28).cuda(),self.y[i].cuda()\n",
    "\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, ds, bs): \n",
    "        self.ds, self.bs = ds, bs\n",
    "    def __iter__(self):\n",
    "        n = len(self.ds)\n",
    "        l = torch.randperm(n)\n",
    "\n",
    "        \n",
    "        for i in range(0, n, self.bs): \n",
    "            idxs_l = l[i:i+self.bs]\n",
    "            yield self.ds[idxs_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ds_from_file(src):\n",
    "    imgs, labels = [], []\n",
    "    \n",
    "    for label in range(10):\n",
    "        path = src/str(label)\n",
    "        print(path)\n",
    "        t = [o.name for o in os.scandir(path)]\n",
    "        t = _get_files(path, t, extensions = [\".jpg\", \".png\"])\n",
    "        for e in t:\n",
    "            l = [np.array(Image.open(e)).reshape(28*28)]\n",
    "            imgs += l\n",
    "        labels += ([label] * len(t))\n",
    "    return torch.tensor(imgs,  dtype=torch.float32), torch.tensor(labels, dtype=torch.long).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dogan\\Desktop\\kodluyoruz_bootcamp_102\\Hafta5\\data\\mnist\\train\\0\n",
      "C:\\Users\\dogan\\Desktop\\kodluyoruz_bootcamp_102\\Hafta5\\data\\mnist\\train\\1\n",
      "C:\\Users\\dogan\\Desktop\\kodluyoruz_bootcamp_102\\Hafta5\\data\\mnist\\train\\2\n",
      "C:\\Users\\dogan\\Desktop\\kodluyoruz_bootcamp_102\\Hafta5\\data\\mnist\\train\\3\n",
      "C:\\Users\\dogan\\Desktop\\kodluyoruz_bootcamp_102\\Hafta5\\data\\mnist\\train\\4\n",
      "C:\\Users\\dogan\\Desktop\\kodluyoruz_bootcamp_102\\Hafta5\\data\\mnist\\train\\5\n",
      "C:\\Users\\dogan\\Desktop\\kodluyoruz_bootcamp_102\\Hafta5\\data\\mnist\\train\\6\n",
      "C:\\Users\\dogan\\Desktop\\kodluyoruz_bootcamp_102\\Hafta5\\data\\mnist\\train\\7\n",
      "C:\\Users\\dogan\\Desktop\\kodluyoruz_bootcamp_102\\Hafta5\\data\\mnist\\train\\8\n",
      "C:\\Users\\dogan\\Desktop\\kodluyoruz_bootcamp_102\\Hafta5\\data\\mnist\\train\\9\n"
     ]
    }
   ],
   "source": [
    "trn_x, trn_y = create_ds_from_file(PATH/\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dogan\\Desktop\\kodluyoruz_bootcamp_102\\Hafta5\\data\\mnist\\validation\\0\n",
      "C:\\Users\\dogan\\Desktop\\kodluyoruz_bootcamp_102\\Hafta5\\data\\mnist\\validation\\1\n",
      "C:\\Users\\dogan\\Desktop\\kodluyoruz_bootcamp_102\\Hafta5\\data\\mnist\\validation\\2\n",
      "C:\\Users\\dogan\\Desktop\\kodluyoruz_bootcamp_102\\Hafta5\\data\\mnist\\validation\\3\n",
      "C:\\Users\\dogan\\Desktop\\kodluyoruz_bootcamp_102\\Hafta5\\data\\mnist\\validation\\4\n",
      "C:\\Users\\dogan\\Desktop\\kodluyoruz_bootcamp_102\\Hafta5\\data\\mnist\\validation\\5\n",
      "C:\\Users\\dogan\\Desktop\\kodluyoruz_bootcamp_102\\Hafta5\\data\\mnist\\validation\\6\n",
      "C:\\Users\\dogan\\Desktop\\kodluyoruz_bootcamp_102\\Hafta5\\data\\mnist\\validation\\7\n",
      "C:\\Users\\dogan\\Desktop\\kodluyoruz_bootcamp_102\\Hafta5\\data\\mnist\\validation\\8\n",
      "C:\\Users\\dogan\\Desktop\\kodluyoruz_bootcamp_102\\Hafta5\\data\\mnist\\validation\\9\n"
     ]
    }
   ],
   "source": [
    "val_x,val_y = create_ds_from_file(PATH/\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(trn_x, trn_y)\n",
    "valid_ds = Dataset(val_x,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, 256)\n",
    "valid_dl = DataLoader(valid_ds, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(x):\n",
    "    print(f\"Mean: {x.mean()}, Std: {x.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Func(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x): \n",
    "        return self.func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):      \n",
    "    return x.view(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_t(x):      \n",
    "    print(x.shape)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain(a):\n",
    "    return math.sqrt(2.0 / (1 + a**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaiming for uniform init\n",
    "def kaiming_uniform(x, a):\n",
    "    n = x[0].shape.numel()\n",
    "    std = gain(a) / math.sqrt(n)\n",
    "    bound = math.sqrt(3.) * std\n",
    "    x.data.uniform_(-bound, bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = nn.Conv2d(1, 8, 5, padding=2,stride=2)\n",
    "kaiming_uniform(l1.weight, a = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "        l1, nn.ReLU(), #14\n",
    "        nn.Conv2d(8, 16, 3, padding=1,stride=2), nn.ReLU(), # 7\n",
    "        nn.Conv2d(16, 27, 3, padding=1,stride=2), nn.ReLU(), # 4\n",
    "#         nn.Conv2d(20, 32, 3, padding=1,stride=2), nn.ReLU(), # 2\n",
    "        #Func(print_t),\n",
    "        nn.AdaptiveMaxPool2d(1),\n",
    "        Func(flatten),\n",
    "        nn.Linear(27,10)\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5555959343910217\n",
      "0.9382267594337463\n",
      "0.9535791873931885\n",
      "0.9659338593482971\n",
      "0.9603015780448914\n",
      "0.9652979373931885\n",
      "0.9683866500854492\n",
      "0.9688408374786377\n"
     ]
    }
   ],
   "source": [
    "train(model,80,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
